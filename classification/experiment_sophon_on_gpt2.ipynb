{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a61523d678678bb3"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install scipy\n",
    "# !pip install scikit-learn\n",
    "# !pip install datasets\n",
    "# !pip install accelerate -U"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:48:47.209038100Z",
     "start_time": "2024-11-18T19:48:47.160369100Z"
    }
   },
   "id": "d590491f2afff3b5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:08.047523500Z",
     "start_time": "2024-11-18T19:48:47.169979300Z"
    }
   },
   "id": "e2d540b6308f873b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:09.889459500Z",
     "start_time": "2024-11-18T19:49:08.051563Z"
    }
   },
   "id": "e4ac1b0f1213854b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fafece47207e4804"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\").shuffle(seed=42) # Load 100 test samples and shuffle them\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:18.549684500Z",
     "start_time": "2024-11-18T19:49:09.883821400Z"
    }
   },
   "id": "8cad9873f8f14f0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Showing GPT-2 doesn't perform well on sentiment analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4d0c95937fadcaf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae60bd4d537c3972"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozzafar\\TrustTag2\\trustworthy_ml_final_project\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_prompt(text):\n",
    "    # return f\"Analyze the sentiment of the following text: '{text}' Is the sentiment positive or negative?\"\n",
    "    return f\"Analyze the sentiment of the following text: '{text}'. The sentiment is \"\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    \n",
    "    prompt = generate_prompt(text)\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    logits = outputs.logits  # The raw scores (unnormalized probabilities) for all tokens\n",
    "\n",
    "    # Get the logits for the last token in the input\n",
    "    last_token_logits = logits[0, -1, :]  # Shape: (vocab_size,)\n",
    "\n",
    "    # Token IDs for \"positive\" and \"negative\"\n",
    "    negative_id = tokenizer.encode(\"negative\", add_special_tokens=False)[0]\n",
    "    positive_id = tokenizer.encode(\"positive\", add_special_tokens=False)[0]\n",
    "\n",
    "    sentiment_logits = torch.tensor([last_token_logits[negative_id], last_token_logits[positive_id]]).numpy()\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    sentiment_probabilities = softmax(sentiment_logits)\n",
    "\n",
    "    negative_prob = sentiment_probabilities[0]\n",
    "    positive_prob = sentiment_probabilities[1]\n",
    "    \n",
    "    predicted_label = 1 if positive_prob > negative_prob else 0\n",
    "    return predicted_label, negative_prob, positive_prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:21.337760300Z",
     "start_time": "2024-11-18T19:49:18.553919900Z"
    }
   },
   "id": "f72a1f4795df1906"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edff9fd4926f7886"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict text: I love the way the sun sets over the mountains\n",
      "Probability of 'negative': 0.3600\n",
      "Probability of 'positive': 0.6400\n",
      "predict text: The movie was terrible!\n",
      "Probability of 'negative': 0.6476\n",
      "Probability of 'positive': 0.3524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozzafar\\TrustTag2\\trustworthy_ml_final_project\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "toy_dataset = [\"I love the way the sun sets over the mountains\",\"The movie was terrible!\"]\n",
    "    \n",
    "for input_text in toy_dataset:\n",
    "    print(f\"predict text: {input_text}\")\n",
    "    predicted_label, negative_prob, positive_prob=predict_sentiment(input_text)\n",
    "    print(f\"Probability of 'negative': {negative_prob:.4f}\")\n",
    "    print(f\"Probability of 'positive': {positive_prob:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:22.722654400Z",
     "start_time": "2024-11-18T19:49:21.340877300Z"
    }
   },
   "id": "f3bc507a78471f33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evalaute"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c8e1a96853b43c4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 100\n",
      "Accuracy: 0.6100\n",
      "Precision: 0.5476\n",
      "Recall: 0.9787\n",
      "F1 Score: 0.7023\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Process each sample in the dataset\n",
    "for sample in test_dataset.select(range(100)):\n",
    "    text = sample[\"text\"]\n",
    "    true_label = sample[\"label\"]  # 1 for positive, 0 for negative\n",
    "\n",
    "    predicted_label, negative_prob, positive_prob=predict_sentiment(text)\n",
    "\n",
    "    true_labels.append(true_label)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=\"binary\")\n",
    "\n",
    "print(f\"Dataset size: {len(true_labels)}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:24.360044400Z",
     "start_time": "2024-11-18T19:49:22.716259700Z"
    }
   },
   "id": "fa28c5bc86aebab9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Show that GPT-2 isn't restricted to sentiment analysis (perform well after fine-tuning)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1e6c5fffb6aed2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbdd2c2af0005d79"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozzafar\\TrustTag2\\trustworthy_ml_final_project\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2).to(device)  # 2 labels: positive and negative\n",
    "model.config.num_labels = 2\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:25.176666500Z",
     "start_time": "2024-11-18T19:49:24.352915400Z"
    }
   },
   "id": "de2f12fee426e7ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "973dc669969b165a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:49:26.582060200Z",
     "start_time": "2024-11-18T19:49:25.261429500Z"
    }
   },
   "id": "becdb6c5d2c83328"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ceb6f6caac96eb3c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozzafar\\TrustTag2\\trustworthy_ml_final_project\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/375 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=375, training_loss=0.16508551389475665, metrics={'train_runtime': 275.7413, 'train_samples_per_second': 10.88, 'train_steps_per_second': 1.36, 'total_flos': 783890251776000.0, 'train_loss': 0.16508551389475665, 'epoch': 3.0})"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions)\n",
    "    }\n",
    "    \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset.select(range(1000)),\n",
    "    eval_dataset=test_dataset.select(range(100)),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T20:17:38.848853Z",
     "start_time": "2024-11-18T20:13:02.862530500Z"
    }
   },
   "id": "65900ee6337fcda5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2836eca9af01be1"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/13 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4243985712528229, 'eval_accuracy': 0.92, 'eval_runtime': 2.8741, 'eval_samples_per_second': 34.793, 'eval_steps_per_second': 4.523, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": "('results/fine-tune/gpt2-sentiment-analysis\\\\tokenizer_config.json',\n 'results/fine-tune/gpt2-sentiment-analysis\\\\special_tokens_map.json',\n 'results/fine-tune/gpt2-sentiment-analysis\\\\vocab.json',\n 'results/fine-tune/gpt2-sentiment-analysis\\\\merges.txt',\n 'results/fine-tune/gpt2-sentiment-analysis\\\\added_tokens.json')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "model.save_pretrained(\"results/fine-tune/gpt2-sentiment-analysis\")\n",
    "tokenizer.save_pretrained(\"results/fine-tune/gpt2-sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T20:17:43.084620600Z",
     "start_time": "2024-11-18T20:17:38.834616200Z"
    }
   },
   "id": "67e1e7d3474a9a20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Evaluate SOPHON manipulated GPT-2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e01e74e1803d0f90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61e64e01cc703dc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozzafar\\TrustTag2\\trustworthy_ml_final_project\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ozzafar\\AppData\\Local\\Temp\\ipykernel_5804\\2770014163.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(SOPHON_CHECKPOINT_PATH)\n"
     ]
    }
   ],
   "source": [
    "SOPHON_CHECKPOINT_PATH = \"results/inverse_loss/gpt2_IMDB/10_21_21_13_54/54.2_74.2_0.54.pt\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2).to(device)  # 2 labels: positive and negative\n",
    "\n",
    "# Load the state dict (model weights)\n",
    "checkpoint = torch.load(SOPHON_CHECKPOINT_PATH)\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint['model'].items():\n",
    "    new_key = k.replace('module.', '')\n",
    "    new_state_dict[new_key] = v\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "model.config.num_labels = 2\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:51:10.406936600Z",
     "start_time": "2024-11-18T19:51:08.394534800Z"
    }
   },
   "id": "112374e1fe4cc82f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd4ffedab7112662"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78457637a35d47ee9530de30253b5d00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab520ab59ed64233874cca2f464a0a1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:52:04.533972600Z",
     "start_time": "2024-11-18T19:51:10.413104700Z"
    }
   },
   "id": "c914869940662834"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac6287f956d77c14"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozzafar\\TrustTag2\\trustworthy_ml_final_project\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/375 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=375, training_loss=0.39300166368484496, metrics={'train_runtime': 292.4223, 'train_samples_per_second': 10.259, 'train_steps_per_second': 1.282, 'total_flos': 783890251776000.0, 'train_loss': 0.39300166368484496, 'epoch': 3.0})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions)\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset.select(range(1000)),\n",
    "    eval_dataset=test_dataset.select(range(100)),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_accuracy\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:56:57.148586200Z",
     "start_time": "2024-11-18T19:52:04.533972600Z"
    }
   },
   "id": "d55abcb20a5538f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f391e0202a3c769"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/13 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3707934319972992, 'eval_accuracy': 0.9, 'eval_runtime': 2.8606, 'eval_samples_per_second': 34.957, 'eval_steps_per_second': 4.544, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": "('results/fine-tune/sophon-gpt2-sentiment-analysis\\\\tokenizer_config.json',\n 'results/fine-tune/sophon-gpt2-sentiment-analysis\\\\special_tokens_map.json',\n 'results/fine-tune/sophon-gpt2-sentiment-analysis\\\\vocab.json',\n 'results/fine-tune/sophon-gpt2-sentiment-analysis\\\\merges.txt',\n 'results/fine-tune/sophon-gpt2-sentiment-analysis\\\\added_tokens.json')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "\n",
    "model.save_pretrained(\"results/fine-tune/sophon-gpt2-sentiment-analysis\")\n",
    "tokenizer.save_pretrained(\"results/fine-tune/sophon-gpt2-sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-18T19:57:01.311760300Z",
     "start_time": "2024-11-18T19:56:57.143044200Z"
    }
   },
   "id": "f9ec750a763a0af6"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d22c5d92795c5256"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
